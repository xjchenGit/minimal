<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="chrome=1">
	<title>About - Xuanjun Chen</title>

	<link rel="stylesheet" href="assets/css/styles.css?v=5">
	<link rel="stylesheet" href="assets/css/header.css">
	<link rel="stylesheet" href="assets/css/logo.css">
	<link rel="stylesheet" href="assets/css/pubs.css?v=47">
	<link rel="stylesheet" href="assets/css/pygment_trac.css">
	<meta name="viewport" content="width=device-width, initial-scale=1" />

	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:wght@300;400;600;700&display=swap"
		rel="stylesheet">
	<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet">
</head>

<body>
	<div class="wrapper">
		<header id="sidebar"></header>

		<section>
			<script src="assets/js/load_header.js"></script>
			<script>initHeader('about');</script>

			<h2>About</h2>

			<p align="justify">
				I am a Ph.D. student at <a href="https://www.ntu.edu.tw/english/" target="_blank">National Taiwan
					University (NTU)</a>,
				advised by <a href="https://speech.ee.ntu.edu.tw/~hylee/index.php" target="_blank">Hung-yi Lee</a> and
				<a href="http://mirlab.org/jang/cv/cv.asp" target="_blank">Jyh-Shing Roger Jang</a>.
				Before Ph.D., I received my M.S. degree from
				<a href="https://www.ntu.edu.tw/english/" target="_blank">NTU</a> (2023) and B.S. degree from <a
					href="https://www.ntust.edu.tw/index.php?Lang=en" target="_blank">Taiwan Tech</a> (2020).
				<!-- I'm honored to receive the <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16"
					viewBox="0 0 48 48">
					<path fill="#EA4335"
						d="M24 9.5c3.54 0 6.71 1.22 9.21 3.6l6.85-6.85C35.9 2.38 30.47 0 24 0 14.62 0 6.51 5.38 2.56 13.22l7.98 6.19C12.43 13.72 17.74 9.5 24 9.5z" />
					<path fill="#4285F4"
						d="M46.98 24.55c0-1.57-.15-3.09-.38-4.55H24v9.02h12.94c-.58 2.96-2.26 5.48-4.78 7.18l7.73 6c4.51-4.18 7.09-10.36 7.09-17.65z" />
					<path fill="#FBBC05"
						d="M10.53 28.59c-.48-1.45-.76-2.99-.76-4.59s.27-3.14.76-4.59l-7.98-6.19C.92 16.46 0 20.12 0 24c0 3.88.92 7.54 2.56 10.78l7.97-6.19z" />
					<path fill="#34A853"
						d="M24 48c6.48 0 11.93-2.13 15.89-5.81l-7.73-6c-2.15 1.45-4.92 2.3-8.16 2.3-6.26 0-11.57-4.22-13.47-9.91l-7.98 6.19C6.51 42.62 14.62 48 24 48z" />
				</svg>
				<strong>Google Student Travel Grant</strong> in 2024. -->
				<!-- I'm honored to receive the
				<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 23 23">
					<path fill="#f35325" d="M0 0h11v11H0z" />
					<path fill="#81bc06" d="M12 0h11v11H12z" />
					<path fill="#05a6f0" d="M0 12h11v11H0z" />
					<path fill="#ffba08" d="M12 12h11v11H12z" />
				</svg>
				<strong>PhD Fellowship</strong>.in 2026.
			</p> -->

			<p align="justify">
				<strong>My research has introduced several approaches for audio deepfakes.</strong> I proposed
				<a href="https://www.isca-archive.org/interspeech_2024/chen24o_interspeech.html"
					target="_blank">SingGraph</a>
				for SOTA SingFake detection and decoded the impact of instrumental accompaniment. To address data
				scarcity,
				I developed <a href="https://arxiv.org/abs/2501.08238" target="_blank">CodecFake+</a>, a large-scale
				resynthesis proxy dataset, and pioneered the source tracing task with
				<a href="https://arxiv.org/abs/2506.07294" target="_blank">SASTNet</a>
				(üèÜ <strong>Best Student Paper Nominee</strong>, IEEE ASRU 2025).
				Concurrently, I have extended my research to <strong>RAG and Audio/Text LLMs</strong>.
				I mentor the development of <strong>GPS-RAG</strong> and <strong>CodaRAG</strong> to optimize efficiency
				and performance;
				our analysis of RAG limitations in <a href="https://aclanthology.org/2025.rocling-main.6/"
					target="_blank">historical archives</a>
				won the üèÜ <strong>Best Paper Award</strong> (ROCLING 2025).
				Last but not least, I also contribute to notable projects in audio understanding, generation, and
				benchmarking, including
				<a href="https://arxiv.org/abs/2507.02768" target="_blank">DeSTA 2.5</a>,
				<a href="https://arxiv.org/abs/2601.14786" target="_blank">SSM-TTM</a>,
				<a href="https://aclanthology.org/2024.findings-acl.616/" target="_blank">Codec-SUPERB</a>,
				and <a href="https://openreview.net/forum?id=s7lzZpAW7T" target="_blank">Dynamic-SUPERB Phase 2</a>.
				I am also grateful to have received the
				<svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 48 48"
					style="vertical-align: middle; margin-bottom: 2px;">
					<path fill="#EA4335"
						d="M24 9.5c3.54 0 6.71 1.22 9.21 3.6l6.85-6.85C35.9 2.38 30.47 0 24 0 14.62 0 6.51 5.38 2.56 13.22l7.98 6.19C12.43 13.72 17.74 9.5 24 9.5z" />
					<path fill="#4285F4"
						d="M46.98 24.55c0-1.57-.15-3.09-.38-4.55H24v9.02h12.94c-.58 2.96-2.26 5.48-4.78 7.18l7.73 6c4.51-4.18 7.09-10.36 7.09-17.65z" />
					<path fill="#FBBC05"
						d="M10.53 28.59c-.48-1.45-.76-2.99-.76-4.59s.27-3.14.76-4.59l-7.98-6.19C.92 16.46 0 20.12 0 24c0 3.88.92 7.54 2.56 10.78l7.97-6.19z" />
					<path fill="#34A853"
						d="M24 48c6.48 0 11.93-2.13 15.89-5.81l-7.73-6c-2.15 1.45-4.92 2.3-8.16 2.3-6.26 0-11.57-4.22-13.47-9.91l-7.98 6.19C6.51 42.62 14.62 48 24 48z" />
				</svg> <strong>Google Student Travel Grant</strong> (2024).
			</p>

			<!-- <div class="experience-logos-long">
					<div class="logo-item-long"><img src="assets/img/ntu_logo_long.png" alt="NTU"></div>
					<div class="logo-item-long"><img src="assets/img/ntust_logo_long.png" alt="TaiwanTech"></div>
				</div> -->

			<!-- <div class="experience-logos">
					<div class="logo-item"><img src="assets/img/ntu_logo.png" alt="NTU"></div>
					<div class="logo-item"><img src="assets/img/ntust_logo_simple.png" alt="TaiwanTech"></div>
				</div> -->

			<h2>Selected Publications <small style="font-size: 14px; font-weight: normal;">(* equal
					contribution)</small></h2>

			<div id="pub-container"></div>

			<!-- YAML parser -->
			<script src="https://cdn.jsdelivr.net/npm/js-yaml@4/dist/js-yaml.min.js"></script>
			<!-- <script src="assets/js/pub-renderer.js"></script> -->
			<!-- ÂèÉÊï∏‰æùÂ∫èÔºöË∑ØÂæë, ÂÆπÂô®ID, ÂàÜÈ°û(null), isIndex(true), onlySelected(true) -->
			<script src="assets/js/2mode-pub-renderer.js?v=15"></script>
			<script>
				// ÂèÉÊï∏Ë™™ÊòéÔºöË∑ØÂæë, ÂÆπÂô®, Category(null), isIndex(true), onlySelected(true), reverseOrder(false)
				loadAndRenderPubs(
					"ymls/publications.yml", // Áµ±‰∏Ä‰ΩøÁî®ÈÄô‰ªΩ YAML
					"pub-container",        // ‰Ω†ÁöÑ HTML ÂÆπÂô® ID
					null,                   // ‰∏çÈôêÈ°ûÂà•ÔºåÈ°ØÁ§∫ÊâÄÊúâ selected È†ÖÁõÆ
					true,                   // ÊòØÈ¶ñÈ†ÅÊ®°Âºè (ÂΩ±Èüø CSS Class)
					true,                   // **ÈóúÈçµÔºöÂè™È°ØÁ§∫ selected È†ÖÁõÆ**
					false,                  // **ÈóúÈçµÔºöÊ≠£Â∫èÊéíÂàó (1, 2, 3...)**
					"ymls/selected_paper.yml" // ‰ΩøÁî®Â§ñÈÉ®ÊéíÂ∫èÊ∏ÖÂñÆ
				);
			</script>

			<h2>Experience</h2>
			<ul>
				<li><span class="desk-text">Sep 2023 - Present:</span><span class="mob-text">09/2023 - Now:</span>
					<b><span class="desk-text">Ph.D. student</span><span class="mob-text">Ph.D.</span></b>
					in <span class="desk-text">Communication
						Engineering</span><span class="mob-text">GICE</span>, National Taiwan University
				</li>
				<li><span class="desk-text">Jan 2023:</span><span class="mob-text">01/2023:</span> <b>M.S.</b> in <span
						class="desk-text">Computer Science</span><span class="mob-text">CSIE</span>, National Taiwan
					University</li>
				<li><span class="desk-text">Jun 2020:</span><span class="mob-text">06/2020:</span> <b>B.S.</b> in <span
						class="desk-text">Computer Science</span><span class="mob-text">CSIE</span>, Taiwan Tech</li>
			</ul>

			<h2>Selected Honors</h2>
			<ul class="honors-list">
				<!-- <ul> -->
				<li>2026: <b>NTU Mr. Wen Tzu-Hsiang Memorial Scholarship</b>, one of only 9 recipients in NTU</li>
				<li>2025: <b>Best Student Paper Nominee</b>, The IEEE Autom. Speech Recognit. and Underst. Workshop</li>
				<li>2025: <b>Best Paper Award</b>, The 37th Conf. on Comput. Linguist. and Speech Processing</li>
				<li>2025: <b>CTCI Foundation Research Scholarship for Overseas Students</b>, awarded by CTCI Foundation
				</li>
				<li>2025: <b>ACLCLP Student Travel Grant</b><span class="mobile-hide-suffix">, granted by ACLCLP.
					</span></li>
				<li>2024: <b>Google Student Travel Grant</b><span class="mobile-hide-suffix">, granted by Google LLC.
					</span></li>
				<li>2024: <b>CTCI Foundation Bursary Award for Overseas Students</b>, awarded by the CTCI Foundation
				</li>
				<li>2021: Ranked <b>3rd/42 submissions worldwide</b> on the LA track of ASVspoof 2021
					challenge</li>
				<!-- <li>2021: Ranked <b>3rd/42 submissions worldwide</b> on the Logical Access track of ASVspoof 2021
					challenge</li> -->
				<li>2020-2025: <b>Kwong Tung Community Outstanding Student Scholarship</b>, awarded five years.</li>
				<li>2018-2020: <b>Certificate of Achievement</b>, Taiwan Tech (Top 5% of students; three semesters)</li>
				<li>2016: <b>National Encouragement Scholarship</b>, awarded by the Ministry of Education</li>
			</ul>

			<h2>Selected Services</h2>
			<ul>
				<li>
					2025: <b>Co-Organizer</b>,
					<a href="https://codecfake.github.io/RespSA-GenAI/">Responsible Speech & Audio Generative AI</a>,
					Special Session at IEEE ASRU 2025
				</li>

				<li>
					2024: <b>Technical Committee</b>,
					<a href="https://codecsuperb.github.io/">Codec-SUPERB Challenge</a>,
					Special Session at IEEE SLT 2024
				</li>

				<li>
					2023‚ÄìNow: <b>Reviewer</b>:
					AAAI, ACL, EMNLP, ICASSP, INTERSPEECH, ASRU, COLING, MLSP, IJPRAI
				</li>
			</ul>

			<!-- <h2>Selected Honors</h2> -->
			<!-- <p align="justify">2025: National Science and Technology Council Conference Subsidy </p> -->
			<!-- <p align="justify">2024-25: (2x) NSTC Student Travel Grant, NSTC Taiwan </p> -->

			<!-- <p align="justify">2025: CTCI Foundation Research Scholarship for Overseas Students</p>
			<p align="justify">2025: ACLCLP Student Travel Grant, ACLCLP Taiwan</p>
			<p align="justify">2024: Google Student Travel Grant, Google LLC </p>
			<p align="justify">2024: CTCI Foundation Bursary Award for Overseas Students</p>
			<p align="justify">2024-25: (2x) NSTC International Academic Conferences Subsidy </p>
			<p align="justify">2020-25: (5x) Kwong Tung Community Outstanding Student Scholarship </p>
			<p align="justify">2021: Ranked 3rd/42 teams in LA track of ASVspoof 2021 challenge </p>
			<p align="justify">2018-20: Certificate of Achievement, Taiwan Tech (Top 5%, 3 semesters)</p>
			<p align="justify">2017: SZIIT Academic Award (3rd Prize), SZIIT</p>
			<p align="justify">2016: National Encouragement Scholarship, Ministry of Education</p> -->

			<!-- <p align="justify">2017: National Bronze Awards, 3rd China College Internet Entrep. Comp. </p> -->
			<!-- <p align="justify">2016-17: National Encouragement Scholarship; 3rd Prize, SZIIT Acad. Award </p> -->
			<!-- <p>2024: National Science and Technology Council (NSTC) Conference Subsidies, NSTC Taiwan </p> -->
			<!-- <p align="justify">2017: National Bronze and Guangdong Provincial Gold Awards, 3rd China College Internet Entrep. Comp. </p> -->
			<!-- <p align="justify">2016: National Encouragement Scholarship</p> -->
			<!-- <p align="justify">2017: 3rd Prize, SZIIT Academic Award</p>
				<p align="justify">2016: National Encouragement Scholarship</p> -->
			<!-- <p align="justify">2016-2017: National Encouragement Scholarship & 3rd Prize, SZIIT Academic Award </p> -->

			<!-- <h2>Selected Serivces</h2>
			<p align="justify">2023-Present: <b>Reviewer/Program Committee</b>, ACL ('24), EMNLP ('24), ICASSP ('23-'25), INTERSPEECH ('25), COLING ('24-'25), MLSP ('24), IALP ('24), ECCV AVGenL ('24)</p> -->
			<!-- <p align="justify">2023-Now: <b>Admin Assistant,</b> <a href="https://nvcenter.ntu.edu.tw/"> NVIDIA-NTU AI Joint Innovation Center</a>, NTU</p> -->
			<!-- <p align="justify">2025: <b>Co-Organizer,</b> <a href="https://codecfake.github.io/RespSA-GenAI/"> Responsible Speech & Audio Generative AI,</a> Special Session at IEEE ASRU 2025</p> -->
			<!-- <p align="justify">2024: <b>Technical Committee</b>, <a href="https://codecsuperb.github.io/">Codec-SUPERB Challenge</a>, Special Session at IEEE SLT 2024</p> -->
			<!-- <p align="justify">2024: <b>Invited Speaker,</b> <a href="https://svddchallenge.org/challenges/special_session_ieee_slt.html">Topic: "Singing Voice Graph Modeling for SingFake Detection,"</a> SVDD Special Session at IEEE SLT 2024</p> -->
			<!-- <p align="justify">2024-25: <b>Teaching Assistant</b>, <a href="https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php"> Intro. to Generative AI</a> & <a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2025-spring.php">Machine Learning</a></p> -->
			<!-- <p align="justify">2023-Now: <b>Reviewer:</b> AAAI, ACL, EMNLP, ICASSP, INTERSPEECH, ASRU, COLING, MLSP, IJPRAI, IALP</p>  -->
			<!-- , ECCV AVGenL -->
			<!-- <br> -->
			<script src="assets/js/mobile-honors-folder.js"></script>
			<br>
			<script type='text/javascript' id='clustrmaps'
				src='https://cdn.clustrmaps.com/map_v2.js?cl=cee3f2&w=200&t=tt&d=nEmSewDPXqNGs14be_z5YYcQJ2bmdcQr14eiveUCbnA&co=ffffff&cmn=005fa3&ct=2d78ad&cmo=980000'></script>

		</section>
	</div>
</body>

</html>